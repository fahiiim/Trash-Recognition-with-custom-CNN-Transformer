{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1417276,"sourceType":"datasetVersion","datasetId":826739}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nimport numpy as np\nimport json\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import resample\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm import tqdm\nimport torch.nn.functional as F\nfrom collections import Counter\n\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Dataset Class\nclass TACODataset(Dataset):\n    def __init__(self, image_paths, labels, transform=None):\n        self.image_paths = image_paths\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        label = self.labels[idx]\n        try:\n            image = Image.open(img_path).convert(\"RGB\")\n            if self.transform:\n                image = self.transform(image)\n            return image, label\n        except Exception as e:\n            print(f\"Error loading image {img_path}: {e}\")\n            blank_image = Image.new('RGB', (224, 224), color='white')\n            if self.transform:\n                blank_image = self.transform(blank_image)\n            else:\n                blank_image = torch.zeros(3, 224, 224)\n            return blank_image, label\n\n# Simplified Multi-Head Self Attention\nclass EnhancedMultiHeadSelfAttention(nn.Module):\n    def __init__(self, embed_dim, num_heads, dropout=0.1):\n        super().__init__()\n        self.embed_dim = embed_dim\n        self.num_heads = num_heads\n        self.head_dim = embed_dim // num_heads\n        \n        assert self.head_dim * num_heads == embed_dim, \"embed_dim must be divisible by num_heads\"\n        \n        self.qkv = nn.Linear(embed_dim, embed_dim * 3)\n        self.attn_dropout = nn.Dropout(dropout)\n        self.proj = nn.Linear(embed_dim, embed_dim)\n        self.proj_dropout = nn.Dropout(dropout)\n        \n    def forward(self, x):\n        B, N, C = x.shape\n        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, self.head_dim).permute(2, 0, 3, 1, 4)\n        q, k, v = qkv[0], qkv[1], qkv[2]\n        \n        attn = (q @ k.transpose(-2, -1)) * (self.head_dim ** -0.5)\n        attn = attn.softmax(dim=-1)\n        attn = self.attn_dropout(attn)\n        \n        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n        x = self.proj(x)\n        x = self.proj_dropout(x)\n        return x\n\n# Simplified Spatial Attention\nclass EnhancedSpatialAttention(nn.Module):\n    def __init__(self, channels):\n        super().__init__()\n        self.conv = nn.Conv2d(2, 1, kernel_size=7, padding=3, bias=False)\n        self.sigmoid = nn.Sigmoid()\n        \n    def forward(self, x):\n        avg_out = torch.mean(x, dim=1, keepdim=True)\n        max_out, _ = torch.max(x, dim=1, keepdim=True)\n        x_attn = torch.cat([avg_out, max_out], dim=1)\n        x_attn = self.conv(x_attn)\n        return x * self.sigmoid(x_attn)\n\n# Simplified Residual Block\nclass EnhancedResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride=1, use_attention=True):\n        super().__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        \n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_channels != out_channels:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, 1, stride=stride, bias=False),\n                nn.BatchNorm2d(out_channels)\n            )\n        \n        self.attention = EnhancedSpatialAttention(out_channels) if use_attention else nn.Identity()\n        \n    def forward(self, x):\n        residual = x\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out = self.attention(out)\n        out += self.shortcut(residual)\n        out = F.relu(out)\n        return out\n\n# Fixed Hybrid Model\nclass UltraDeepHybridCNNTransformer(nn.Module):\n    def __init__(self, num_classes=5, img_size=224, patch_size=7, embed_dim=512, depth=4, num_heads=8):\n        super().__init__()\n        \n        # CNN Backbone\n        self.stem = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)  # 56x56\n        )\n        \n        self.block1 = nn.Sequential(\n            EnhancedResidualBlock(64, 64),\n            EnhancedResidualBlock(64, 128, stride=2)  # 28x28\n        )\n        \n        self.block2 = nn.Sequential(\n            EnhancedResidualBlock(128, 128),\n            EnhancedResidualBlock(128, 256, stride=2)  # 14x14\n        )\n        \n        self.block3 = nn.Sequential(\n            EnhancedResidualBlock(256, 256),\n            EnhancedResidualBlock(256, 512, stride=1)  # 14x14\n        )\n        \n        # Patch embedding\n        self.patch_size = patch_size\n        self.num_patches = (14 // patch_size) ** 2\n        self.patch_embed = nn.Conv2d(512, embed_dim, kernel_size=patch_size, stride=patch_size)\n        \n        # Positional embedding and CLS token\n        self.pos_embed = nn.Parameter(torch.zeros(1, self.num_patches + 1, embed_dim))\n        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n        \n        # Transformer layers\n        self.transformer_layers = nn.ModuleList([\n            nn.ModuleDict({\n                'norm1': nn.LayerNorm(embed_dim),\n                'attn': EnhancedMultiHeadSelfAttention(embed_dim, num_heads),\n                'norm2': nn.LayerNorm(embed_dim),\n                'mlp': nn.Sequential(\n                    nn.Linear(embed_dim, embed_dim * 4),\n                    nn.GELU(),\n                    nn.Linear(embed_dim * 4, embed_dim),\n                )\n            }) for _ in range(depth)\n        ])\n        \n        # Classification head\n        self.norm = nn.LayerNorm(embed_dim)\n        self.head = nn.Linear(embed_dim, num_classes)\n        \n        # Initialize weights\n        self._init_weights()\n    \n    def _init_weights(self):\n        for name, m in self.named_modules():\n            if isinstance(m, nn.Linear):\n                nn.init.trunc_normal_(m.weight, std=0.02)\n                if m.bias is not None:\n                    nn.init.zeros_(m.bias)\n            elif isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n            elif isinstance(m, (nn.BatchNorm2d, nn.LayerNorm)):\n                nn.init.ones_(m.weight)\n                nn.init.zeros_(m.bias)\n        \n        nn.init.trunc_normal_(self.pos_embed, std=0.02)\n        nn.init.trunc_normal_(self.cls_token, std=0.02)\n\n    def forward(self, x):\n        # CNN feature extraction\n        x = self.stem(x)      # 56x56\n        x = self.block1(x)    # 28x28\n        x = self.block2(x)    # 14x14\n        x = self.block3(x)    # 14x14\n        \n        # Patch embedding\n        x = self.patch_embed(x)  # (B, embed_dim, num_patches_h, num_patches_w)\n        x = x.flatten(2).transpose(1, 2)  # (B, num_patches, embed_dim)\n        \n        # Add CLS token and positional embedding\n        cls_tokens = self.cls_token.expand(x.shape[0], -1, -1)\n        x = torch.cat((cls_tokens, x), dim=1)\n        x = x + self.pos_embed\n        \n        # Transformer encoding\n        for layer in self.transformer_layers:\n            x = x + layer['attn'](layer['norm1'](x))\n            x = x + layer['mlp'](layer['norm2'](x))\n        \n        # Classification\n        x = self.norm(x[:, 0])  # CLS token\n        return self.head(x)\n\n# Data Loading and Balancing\ndef load_and_balance_taco_data(data_dir, anno_path):\n    with open(anno_path, \"r\") as f:\n        annotations = json.load(f)\n    \n    category_mapping = {\n        \"plastic\": 0, \"metal\": 1, \"paper\": 2, \"glass\": 3, \"organic\": 4,\n        \"bottle\": 0, \"can\": 1, \"cardboard\": 2, \"jar\": 3, \"food\": 4\n    }\n    \n    image_paths = []\n    labels = []\n    cat_id_to_name = {cat['id']: cat['name'] for cat in annotations['categories']}\n    \n    for img in annotations['images']:\n        img_path = os.path.join(data_dir, img['file_name'])\n        if os.path.exists(img_path):\n            for ann in annotations['annotations']:\n                if ann['image_id'] == img['id']:\n                    category_name = cat_id_to_name[ann['category_id']].lower()\n                    for key, value in category_mapping.items():\n                        if key in category_name:\n                            image_paths.append(img_path)\n                            labels.append(value)\n                            break\n    \n    # Convert to numpy arrays for balancing\n    image_paths_np = np.array(image_paths)\n    labels_np = np.array(labels)\n    \n    # Balance classes\n    unique_classes, class_counts = np.unique(labels_np, return_counts=True)\n    max_samples = max(class_counts) * 2  # Oversample\n    \n    balanced_paths = []\n    balanced_labels = []\n    \n    for cls in unique_classes:\n        cls_mask = (labels_np == cls)\n        cls_paths = image_paths_np[cls_mask]\n        cls_labels = labels_np[cls_mask]\n        \n        upsampled_paths, upsampled_labels = resample(\n            cls_paths, cls_labels, \n            n_samples=max_samples, \n            random_state=42,\n            replace=True\n        )\n        \n        balanced_paths.extend(upsampled_paths.tolist())\n        balanced_labels.extend(upsampled_labels.tolist())\n    \n    return balanced_paths, balanced_labels\n\n# Training Function\ndef train_model(model, train_loader, val_loader, num_epochs=50):\n    # Class weighting\n    class_counts = Counter(train_loader.dataset.labels)\n    total_samples = sum(class_counts.values())\n    class_weights = torch.tensor([total_samples / class_counts[i] for i in range(len(class_counts))]).float().to(device)\n    \n    criterion = nn.CrossEntropyLoss(weight=class_weights)\n    optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n    scheduler = ReduceLROnPlateau(optimizer, 'max', patience=3, factor=0.5, verbose=True)\n    \n    train_acc = []\n    val_acc = []\n    best_val_acc = 0.0\n    patience = 10\n    patience_counter = 0\n    \n    for epoch in range(num_epochs):\n        model.train()\n        correct = 0\n        total = 0\n        \n        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n        for images, labels in progress_bar:\n            images, labels = images.to(device), labels.to(device)\n            \n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n            optimizer.step()\n            \n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            \n            progress_bar.set_postfix({\n                'Loss': f'{loss.item():.4f}',\n                'Acc': f'{100 * correct / total:.2f}%'\n            })\n        \n        train_acc.append(100 * correct / total)\n        \n        # Validation\n        model.eval()\n        val_correct = 0\n        val_total = 0\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                _, predicted = torch.max(outputs.data, 1)\n                val_total += labels.size(0)\n                val_correct += (predicted == labels).sum().item()\n        \n        val_acc.append(100 * val_correct / val_total)\n        scheduler.step(val_acc[-1])\n        \n        # Early stopping\n        if val_acc[-1] > best_val_acc:\n            best_val_acc = val_acc[-1]\n            torch.save(model.state_dict(), 'best_model.pth')\n            patience_counter = 0\n        else:\n            patience_counter += 1\n        \n        print(f\"Epoch {epoch+1}/{num_epochs}\")\n        print(f\"Train Acc: {train_acc[-1]:.2f}%, Val Acc: {val_acc[-1]:.2f}%\")\n        print(f\"Best Val Acc: {best_val_acc:.2f}%\")\n        print(\"-\" * 50)\n        \n        if patience_counter >= patience:\n            print(f\"Early stopping at epoch {epoch+1}\")\n            break\n    \n    # Plot training curves\n    plt.figure(figsize=(12, 5))\n    plt.subplot(1, 2, 1)\n    plt.plot(train_acc, label='Train Acc')\n    plt.plot(val_acc, label='Val Acc')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy (%)')\n    plt.legend()\n    \n    plt.tight_layout()\n    plt.savefig('training_curves.png')\n    plt.show()\n    \n    return best_val_acc\n\ndef main():\n    # Data paths\n    data_dir = \"/kaggle/input/tacotrashdataset/data\"\n    anno_path = \"/kaggle/input/tacotrashdataset/data/annotations.json\"\n\n    # Load and balance data\n    print(\"Loading and balancing TACO dataset...\")\n    image_paths, labels = load_and_balance_taco_data(data_dir, anno_path)\n    \n    if not image_paths:\n        raise ValueError(\"No valid images found in dataset\")\n\n    print(f\"Loaded {len(image_paths)} images after balancing\")\n    \n    # Get number of classes\n    unique_labels = sorted(list(set(labels)))\n    num_classes = len(unique_labels)\n    print(f\"Number of classes found: {num_classes}\")\n    print(f\"Classes: {unique_labels}\")\n\n    # Data transforms\n    train_transform = transforms.Compose([\n        transforms.Resize((256, 256)),\n        transforms.RandomResizedCrop(224, scale=(0.6, 1.0)),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.RandomRotation(45),\n        transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        transforms.RandomErasing(p=0.3, scale=(0.02, 0.33), ratio=(0.3, 3.3))\n    ])\n\n    val_transform = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n\n    # Split data\n    train_paths, test_paths, train_labels, test_labels = train_test_split(\n        image_paths, labels, test_size=0.2, stratify=labels, random_state=42\n    )\n    val_paths, test_paths, val_labels, test_labels = train_test_split(\n        test_paths, test_labels, test_size=0.5, stratify=test_labels, random_state=42\n    )\n\n    # Create datasets\n    train_dataset = TACODataset(train_paths, train_labels, transform=train_transform)\n    val_dataset = TACODataset(val_paths, val_labels, transform=val_transform)\n    test_dataset = TACODataset(test_paths, test_labels, transform=val_transform)\n\n    # Data loaders\n    train_loader = DataLoader(\n        train_dataset, batch_size=32, shuffle=True,\n        num_workers=4, pin_memory=True\n    )\n    val_loader = DataLoader(\n        val_dataset, batch_size=32, shuffle=False,\n        num_workers=4, pin_memory=True\n    )\n    test_loader = DataLoader(\n        test_dataset, batch_size=32, shuffle=False,\n        num_workers=4, pin_memory=True\n    )\n\n    # Model\n    print(\"Creating simplified hybrid model...\")\n    model = UltraDeepHybridCNNTransformer(\n        num_classes=num_classes,\n        embed_dim=512,\n        depth=4,\n        num_heads=8,\n        patch_size=7\n    ).to(device)\n\n    # Model summary\n    total_params = sum(p.numel() for p in model.parameters())\n    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    print(f\"Total parameters: {total_params:,}\")\n    print(f\"Trainable parameters: {trainable_params:,}\")\n\n    # Train model\n    print(\"\\nStarting training...\")\n    best_val_acc = train_model(model, train_loader, val_loader, num_epochs=50)\n    print(f\"Best validation accuracy: {best_val_acc:.2f}%\")\n\n    # Load best model\n    model.load_state_dict(torch.load('best_model.pth'))\n\n    # Evaluation\n    print(\"\\nEvaluating on test set...\")\n    model.eval()\n    predictions = []\n    true_labels = []\n    \n    with torch.no_grad():\n        for images, labels in tqdm(test_loader, desc=\"Testing\"):\n            images = images.to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            \n            predictions.extend(predicted.cpu().numpy())\n            true_labels.extend(labels.numpy())\n\n    # Metrics\n    acc = accuracy_score(true_labels, predictions)\n    f1 = f1_score(true_labels, predictions, average='weighted')\n    print(f\"\\nTest Accuracy: {acc:.4f}\")\n    print(f\"Weighted F1 Score: {f1:.4f}\")\n\n    # Classification report\n    class_names = ['Plastic', 'Metal', 'Paper', 'Glass', 'Organic']\n    actual_class_names = [class_names[i] for i in unique_labels]\n    \n    print(\"\\nClassification Report:\")\n    print(classification_report(\n        true_labels, predictions, \n        labels=unique_labels,\n        target_names=actual_class_names\n    ))\n\n    # Confusion Matrix\n    cm = confusion_matrix(true_labels, predictions, labels=unique_labels)\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n                xticklabels=actual_class_names, \n                yticklabels=actual_class_names)\n    plt.title(f'Confusion Matrix\\nTest Accuracy: {acc:.3f}')\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.tight_layout()\n    plt.savefig('confusion_matrix.png')\n    plt.show()\n\nif __name__ == \"__main__\":\n    main()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-14T18:13:23.887045Z","iopub.execute_input":"2025-08-14T18:13:23.887342Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nLoading and balancing TACO dataset...\nLoaded 19150 images after balancing\nNumber of classes found: 5\nClasses: [0, 1, 2, 3, 4]\nCreating simplified hybrid model...\nTotal parameters: 31,844,241\nTrainable parameters: 31,844,241\n\nStarting training...\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/50: 100%|██████████| 479/479 [10:36<00:00,  1.33s/it, Loss=1.4871, Acc=25.93%]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50\nTrain Acc: 25.93%, Val Acc: 30.86%\nBest Val Acc: 30.86%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/50: 100%|██████████| 479/479 [10:34<00:00,  1.32s/it, Loss=1.4142, Acc=32.52%]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/50\nTrain Acc: 32.52%, Val Acc: 40.57%\nBest Val Acc: 40.57%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/50: 100%|██████████| 479/479 [10:33<00:00,  1.32s/it, Loss=1.3537, Acc=36.93%]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/50\nTrain Acc: 36.93%, Val Acc: 44.96%\nBest Val Acc: 44.96%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/50: 100%|██████████| 479/479 [10:37<00:00,  1.33s/it, Loss=1.3104, Acc=39.54%]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4/50\nTrain Acc: 39.54%, Val Acc: 45.33%\nBest Val Acc: 45.33%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/50: 100%|██████████| 479/479 [10:59<00:00,  1.38s/it, Loss=1.5866, Acc=42.23%]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5/50\nTrain Acc: 42.23%, Val Acc: 49.87%\nBest Val Acc: 49.87%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/50: 100%|██████████| 479/479 [10:54<00:00,  1.37s/it, Loss=1.5455, Acc=44.34%]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6/50\nTrain Acc: 44.34%, Val Acc: 48.41%\nBest Val Acc: 49.87%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/50: 100%|██████████| 479/479 [10:54<00:00,  1.37s/it, Loss=1.5101, Acc=46.37%]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7/50\nTrain Acc: 46.37%, Val Acc: 53.32%\nBest Val Acc: 53.32%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/50: 100%|██████████| 479/479 [10:57<00:00,  1.37s/it, Loss=1.1311, Acc=48.51%]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8/50\nTrain Acc: 48.51%, Val Acc: 55.67%\nBest Val Acc: 55.67%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/50: 100%|██████████| 479/479 [10:57<00:00,  1.37s/it, Loss=1.4632, Acc=50.60%]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9/50\nTrain Acc: 50.60%, Val Acc: 57.60%\nBest Val Acc: 57.60%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/50: 100%|██████████| 479/479 [11:03<00:00,  1.38s/it, Loss=1.0276, Acc=51.30%]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10/50\nTrain Acc: 51.30%, Val Acc: 58.96%\nBest Val Acc: 58.96%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/50: 100%|██████████| 479/479 [10:49<00:00,  1.36s/it, Loss=1.4062, Acc=52.50%]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11/50\nTrain Acc: 52.50%, Val Acc: 58.80%\nBest Val Acc: 58.96%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12/50: 100%|██████████| 479/479 [10:59<00:00,  1.38s/it, Loss=0.9381, Acc=54.28%]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12/50\nTrain Acc: 54.28%, Val Acc: 57.96%\nBest Val Acc: 58.96%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13/50: 100%|██████████| 479/479 [10:50<00:00,  1.36s/it, Loss=0.9685, Acc=55.08%]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13/50\nTrain Acc: 55.08%, Val Acc: 61.78%\nBest Val Acc: 61.78%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14/50: 100%|██████████| 479/479 [10:49<00:00,  1.36s/it, Loss=1.1410, Acc=55.50%]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14/50\nTrain Acc: 55.50%, Val Acc: 60.84%\nBest Val Acc: 61.78%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15/50: 100%|██████████| 479/479 [10:48<00:00,  1.35s/it, Loss=1.0414, Acc=56.76%]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15/50\nTrain Acc: 56.76%, Val Acc: 64.44%\nBest Val Acc: 64.44%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16/50: 100%|██████████| 479/479 [10:59<00:00,  1.38s/it, Loss=0.8399, Acc=58.30%]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 16/50\nTrain Acc: 58.30%, Val Acc: 62.51%\nBest Val Acc: 64.44%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17/50: 100%|██████████| 479/479 [11:00<00:00,  1.38s/it, Loss=0.8600, Acc=58.49%]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 17/50\nTrain Acc: 58.49%, Val Acc: 65.48%\nBest Val Acc: 65.48%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18/50: 100%|██████████| 479/479 [10:58<00:00,  1.37s/it, Loss=0.8684, Acc=59.51%]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 18/50\nTrain Acc: 59.51%, Val Acc: 68.15%\nBest Val Acc: 68.15%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19/50: 100%|██████████| 479/479 [10:57<00:00,  1.37s/it, Loss=0.9139, Acc=59.92%]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 19/50\nTrain Acc: 59.92%, Val Acc: 66.58%\nBest Val Acc: 68.15%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20/50: 100%|██████████| 479/479 [10:55<00:00,  1.37s/it, Loss=0.5949, Acc=61.02%]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 20/50\nTrain Acc: 61.02%, Val Acc: 67.36%\nBest Val Acc: 68.15%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 21/50: 100%|██████████| 479/479 [10:45<00:00,  1.35s/it, Loss=1.7531, Acc=61.93%]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 21/50\nTrain Acc: 61.93%, Val Acc: 67.57%\nBest Val Acc: 68.15%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 22/50: 100%|██████████| 479/479 [10:58<00:00,  1.37s/it, Loss=0.9977, Acc=62.63%]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 22/50\nTrain Acc: 62.63%, Val Acc: 72.85%\nBest Val Acc: 72.85%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 23/50: 100%|██████████| 479/479 [11:20<00:00,  1.42s/it, Loss=0.8094, Acc=63.89%]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 23/50\nTrain Acc: 63.89%, Val Acc: 71.49%\nBest Val Acc: 72.85%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 24/50: 100%|██████████| 479/479 [11:20<00:00,  1.42s/it, Loss=1.0469, Acc=63.98%]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 24/50\nTrain Acc: 63.98%, Val Acc: 72.06%\nBest Val Acc: 72.85%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 25/50: 100%|██████████| 479/479 [11:15<00:00,  1.41s/it, Loss=0.9727, Acc=64.65%]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 25/50\nTrain Acc: 64.65%, Val Acc: 73.32%\nBest Val Acc: 73.32%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 26/50: 100%|██████████| 479/479 [11:16<00:00,  1.41s/it, Loss=0.6220, Acc=65.61%]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 26/50\nTrain Acc: 65.61%, Val Acc: 71.17%\nBest Val Acc: 73.32%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 27/50: 100%|██████████| 479/479 [11:15<00:00,  1.41s/it, Loss=1.0185, Acc=65.91%]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 27/50\nTrain Acc: 65.91%, Val Acc: 70.50%\nBest Val Acc: 73.32%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 28/50: 100%|██████████| 479/479 [11:00<00:00,  1.38s/it, Loss=0.8193, Acc=66.91%]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 28/50\nTrain Acc: 66.91%, Val Acc: 73.16%\nBest Val Acc: 73.32%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 29/50: 100%|██████████| 479/479 [11:07<00:00,  1.39s/it, Loss=0.9119, Acc=67.44%]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 29/50\nTrain Acc: 67.44%, Val Acc: 73.84%\nBest Val Acc: 73.84%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 30/50: 100%|██████████| 479/479 [11:02<00:00,  1.38s/it, Loss=1.3879, Acc=67.69%]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 30/50\nTrain Acc: 67.69%, Val Acc: 73.73%\nBest Val Acc: 73.84%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 31/50: 100%|██████████| 479/479 [11:06<00:00,  1.39s/it, Loss=0.7174, Acc=68.58%]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 31/50\nTrain Acc: 68.58%, Val Acc: 71.75%\nBest Val Acc: 73.84%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 32/50: 100%|██████████| 479/479 [11:18<00:00,  1.42s/it, Loss=0.5920, Acc=68.94%]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 32/50\nTrain Acc: 68.94%, Val Acc: 74.78%\nBest Val Acc: 74.78%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 33/50: 100%|██████████| 479/479 [11:18<00:00,  1.42s/it, Loss=0.6462, Acc=68.75%]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 33/50\nTrain Acc: 68.75%, Val Acc: 75.35%\nBest Val Acc: 75.35%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 34/50: 100%|██████████| 479/479 [11:12<00:00,  1.40s/it, Loss=0.9881, Acc=69.99%]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 34/50\nTrain Acc: 69.99%, Val Acc: 78.59%\nBest Val Acc: 78.59%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 35/50: 100%|██████████| 479/479 [10:49<00:00,  1.36s/it, Loss=0.9932, Acc=69.98%]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 35/50\nTrain Acc: 69.98%, Val Acc: 78.17%\nBest Val Acc: 78.59%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 36/50: 100%|██████████| 479/479 [10:41<00:00,  1.34s/it, Loss=0.7637, Acc=70.92%]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 36/50\nTrain Acc: 70.92%, Val Acc: 78.12%\nBest Val Acc: 78.59%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 37/50: 100%|██████████| 479/479 [10:43<00:00,  1.34s/it, Loss=0.4127, Acc=70.82%]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 37/50\nTrain Acc: 70.82%, Val Acc: 78.59%\nBest Val Acc: 78.59%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 38/50: 100%|██████████| 479/479 [10:58<00:00,  1.38s/it, Loss=0.6533, Acc=71.64%]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 38/50\nTrain Acc: 71.64%, Val Acc: 76.71%\nBest Val Acc: 78.59%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 39/50: 100%|██████████| 479/479 [10:48<00:00,  1.35s/it, Loss=0.6408, Acc=74.03%]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 39/50\nTrain Acc: 74.03%, Val Acc: 79.32%\nBest Val Acc: 79.32%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 40/50: 100%|██████████| 479/479 [10:47<00:00,  1.35s/it, Loss=0.5803, Acc=74.85%]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 40/50\nTrain Acc: 74.85%, Val Acc: 78.17%\nBest Val Acc: 79.32%\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Epoch 41/50:  61%|██████    | 292/479 [06:36<02:37,  1.19it/s, Loss=0.5367, Acc=74.91%]","output_type":"stream"}],"execution_count":null}]}